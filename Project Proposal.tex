\documentclass[]{article}

%opening
\title{Project Proposal}
\author{Katie Winkle}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Aims and Objectives}
\section{Motivation}
\section{Literature Review}

[Psychology Background/Results]

There are multiple theories concerning the social function of human emotion at the individual, dyadic, group and cultural level, based on the observed consequences they have for those groups \cite{keltner1999social}. For example... (fear contagion, information about environment etc references from keltner + others). This demonstrates the importance of emotional expression in human-human interaction and hence justifies its study in HRI. 

[insight into the importance of emotional expression in human interaction and hence relevant to hri...or...demonstrates huge potential impact of emotional expression (e.g fear contagion) so basically here justify the need to understand and desire to use emotional expression in hri and maybe even more so in assisted living type] applications.

It has been demonstrated that movement alone can express emotion even when static information is minimised, e.g. \cite{dittrich1996perception}, \cite{pollick2001perceiving}, Atkinson 2004 (affect folder of papers) [...] hence the way in which communication gestures are executed by the robot is likely to be important in emotion expression. lending credibility to this is the result found by XXX that the presence and pose of a robot body significantly increases emotion percievability compared to facial expression alone. ...maybe something about how this allows for emotional expression even in robots which do not have facial features etc.  

[Robot Applications/Work]

Lim et al. demonstrated a framework for dynamically mapping the emotion in a speech sample to robot gesturing \cite{lim2011converting}. Four parameters are identified that can be measured in the speech sample and applied to the robot's gesture; these are speed, intensity, regularity and extent (SIRE). For example, speed is measured by the speech rate of the voice sample and applied to the velocity of the gesture. The use of SIRE means that the emotional communication is pose-independent [contrasting with other research looking at specific gestures like arms up for surprise?]. Additionally, this is relatively simple(?) [compared to emotion generation models] because the robot requires no internal emotional state model. The framework was used to parameterise an example gesture on the NAO [more details on robot?] using actor speech samples and experiments were set up in order to test whether the resulting gesture successfully conveyed the emotional content of the original speech. The results suggest that changing the dynamics of a gesture, according to SIRE, can produce recognisable emotions at an inter-rater agreement of above 60\%. However, it was shown that in playing the original speech sample through the robot alongside the gesture had different impacts on different emotion, for example happiness was much easier to understand but anger was much harder. The authors hypothesised that this could be due to the neutral stance of the NAO, suggesting that whilst their method is designed to be independent of pose, the choice of gesture and pose is likely to be of importance in successfully conveying the desired emotion.

Lim et al. demonstrated a framework for mapping the emotion in a speech sample to robot gesturing based on four parameters;  speed, intensity, regularity and extent (SIRE) \cite{lim2011converting}. This is based on the concept that the motion of gesturing rather than the shape of gestures themselves can convey emotion and is more realistic for natural communication. A major benefit of this approach is that the robot requires no internal state model and can instead produce a more continuous emotional XXX, which again might be more natural according to some human emotion studies.  


\section{Risk Register}
\section{Timeline}

\end{document}
